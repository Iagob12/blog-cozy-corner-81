"""
Sistema Autom√°tico Completo

Gerencia todo o fluxo automaticamente:
1. An√°lise inicial com consenso (3x)
2. Detec√ß√£o de releases novos
3. Atualiza√ß√£o autom√°tica do ranking
4. Detec√ß√£o de CSV novo
"""
import asyncio
import json
import os
from datetime import datetime, timedelta
from typing import List, Dict, Optional
from collections import Counter
import hashlib


class SistemaAutomatico:
    """
    Sistema totalmente autom√°tico que:
    - Executa an√°lise ao iniciar
    - Valida por consenso (3x)
    - Detecta releases novos
    - Atualiza ranking automaticamente
    - Detecta CSV novo e refaz processo
    """
    
    def __init__(self):
        self.config_file = "data/sistema_config.json"
        self.empresas_file = "data/empresas_aprovadas.json"
        self.ranking_file = "data/ranking_cache.json"
        self.csv_hash_file = "data/csv_hash.txt"
        
        self.config = self._carregar_config()
        
        print("‚úì Sistema Autom√°tico inicializado")
    
    def _carregar_config(self) -> Dict:
        """Carrega configura√ß√£o do sistema"""
        if os.path.exists(self.config_file):
            try:
                with open(self.config_file, 'r', encoding='utf-8-sig') as f:
                    return json.load(f)
            except:
                pass
        
        return {
            "analise_inicial_completa": False,
            "empresas_confirmadas": False,
            "ultima_analise": None,
            "csv_hash": None,
            "tentativas_consenso": 1,  # 1 tentativa por padr√£o (mais r√°pido)
            "threshold_consenso": 0.7  # 70% das empresas devem aparecer em todas an√°lises
        }
    
    def _salvar_config(self):
        """Salva configura√ß√£o"""
        try:
            os.makedirs("data", exist_ok=True)
            with open(self.config_file, 'w', encoding='utf-8') as f:
                json.dump(self.config, f, indent=2, ensure_ascii=False)
        except Exception as e:
            print(f"‚ö†Ô∏è Erro ao salvar config: {e}")
    
    def _calcular_hash_csv(self, csv_path: str = "data/stocks.csv") -> Optional[str]:
        """Calcula hash do CSV para detectar mudan√ßas"""
        try:
            if not os.path.exists(csv_path):
                return None
            
            with open(csv_path, 'rb') as f:
                return hashlib.md5(f.read()).hexdigest()
        except:
            return None
    
    def csv_mudou(self, csv_path: str = "data/stocks.csv") -> bool:
        """Verifica se CSV mudou desde √∫ltima an√°lise"""
        hash_atual = self._calcular_hash_csv(csv_path)
        hash_anterior = self.config.get("csv_hash")
        
        if not hash_anterior:
            return True  # Primeira vez
        
        return hash_atual != hash_anterior
    
    async def executar_analise_com_consenso(
        self,
        tentativas: int = 1,
        threshold: float = 0.7
    ) -> Dict:
        """
        Executa an√°lise usando sistema incremental (SEM yfinance)
        
        SIMPLIFICADO: Usa apenas dados do CSV + releases
        
        Args:
            tentativas: N√∫mero de an√°lises (1 = sem consenso, mais r√°pido)
            threshold: % m√≠nimo de empresas que devem aparecer em todas
        
        Returns:
            Empresas aprovadas
        """
        print(f"\n{'='*70}")
        print(f"üîÑ AN√ÅLISE INCREMENTAL (CSV + Releases)")
        print(f"{'='*70}\n")
        
        # Carrega empresas do arquivo (j√° foram selecionadas antes)
        if os.path.exists(self.empresas_file):
            with open(self.empresas_file, 'r', encoding='utf-8-sig') as f:
                dados = json.load(f)
            empresas = dados.get("empresas", [])
            
            if empresas:
                print(f"‚úì Usando {len(empresas)} empresas j√° aprovadas")
                
                # Executa an√°lise incremental
                from app.services.analise_automatica import get_analise_automatica_service
                service = get_analise_automatica_service()
                
                resultado = await service.analisar_incrementalmente(
                    empresas=empresas,
                    forcar_reanalise=True,  # For√ßa rean√°lise
                    max_paralelo=1  # 1 por vez (evita rate limit)
                )
                
                print(f"\n‚úÖ AN√ÅLISE CONCLU√çDA")
                print(f"   Analisadas: {resultado['novas_analises']}")
                print(f"   Falhas: {resultado['falhas']}")
                print(f"   Total no ranking: {resultado['total_ranking']}")
                
                return {
                    "empresas": empresas,
                    "total": len(empresas),
                    "tentativas": 1,
                    "threshold": 1.0
                }
        
        # Se n√£o tem empresas aprovadas, retorna vazio
        print("‚ö†Ô∏è Nenhuma empresa aprovada encontrada")
        return {
            "empresas": [],
            "total": 0,
            "tentativas": 0,
            "threshold": 0
        }
    
    def _calcular_consenso(
        self,
        todas_empresas: List[List[str]],
        threshold: float
    ) -> List[str]:
        """
        Calcula consenso entre m√∫ltiplas an√°lises
        
        Retorna apenas empresas que aparecem em pelo menos threshold% das an√°lises
        """
        # Conta quantas vezes cada empresa aparece
        contador = Counter()
        for empresas in todas_empresas:
            for empresa in empresas:
                contador[empresa] += 1
        
        # Calcula threshold m√≠nimo
        min_aparicoes = int(len(todas_empresas) * threshold)
        
        # Filtra empresas que atingem threshold
        empresas_consenso = [
            empresa
            for empresa, count in contador.items()
            if count >= min_aparicoes
        ]
        
        # Ordena por frequ√™ncia (mais frequentes primeiro)
        empresas_consenso.sort(
            key=lambda e: contador[e],
            reverse=True
        )
        
        # Log detalhado
        print(f"üìä An√°lise de Consenso:")
        print(f"   Total de an√°lises: {len(todas_empresas)}")
        print(f"   Threshold: {threshold*100}% ({min_aparicoes} apari√ß√µes)")
        print(f"   Empresas √∫nicas: {len(contador)}")
        print(f"   Empresas no consenso: {len(empresas_consenso)}")
        
        # Mostra top 10 mais frequentes
        print(f"\n   Top 10 mais frequentes:")
        for empresa in list(empresas_consenso)[:10]:
            freq = contador[empresa]
            pct = (freq / len(todas_empresas)) * 100
            print(f"      {empresa}: {freq}/{len(todas_empresas)} ({pct:.0f}%)")
        
        return empresas_consenso
    
    async def iniciar_sistema_automatico(self):
        """
        Inicia sistema autom√°tico completo
        
        Fluxo SIMPLIFICADO (sem yfinance):
        1. Verifica se j√° tem empresas aprovadas
        2. Se sim: executa an√°lise incremental (CSV + releases)
        3. Se n√£o: usa empresas do arquivo existente
        """
        print(f"\n{'='*70}")
        print(f"üöÄ INICIANDO SISTEMA AUTOM√ÅTICO")
        print(f"{'='*70}\n")
        
        # Verifica se j√° tem empresas aprovadas
        if os.path.exists(self.empresas_file):
            with open(self.empresas_file, 'r', encoding='utf-8-sig') as f:
                dados = json.load(f)
            
            empresas = dados.get("empresas", [])
            
            if empresas and len(empresas) > 0:
                print(f"‚úì {len(empresas)} empresas j√° aprovadas")
                print(f"üìä Executando an√°lise incremental (CSV + releases)")
                
                try:
                    # Executa an√°lise incremental
                    from app.services.analise_automatica import get_analise_automatica_service
                    service = get_analise_automatica_service()
                    
                    resultado = await service.analisar_incrementalmente(
                        empresas=empresas,
                        forcar_reanalise=True,  # For√ßa rean√°lise
                        max_paralelo=1  # 1 por vez (evita rate limit)
                    )
                    
                    # Atualiza config
                    self.config["analise_inicial_completa"] = True
                    self.config["empresas_confirmadas"] = True
                    self.config["ultima_analise"] = datetime.now().isoformat()
                    self.config["csv_hash"] = self._calcular_hash_csv()
                    self._salvar_config()
                    
                    print(f"\n{'='*70}")
                    print(f"‚úÖ SISTEMA AUTOM√ÅTICO PRONTO")
                    print(f"{'='*70}")
                    print(f"üìä {len(empresas)} empresas analisadas")
                    print(f"‚úì Novas an√°lises: {resultado['novas_analises']}")
                    print(f"‚ùå Falhas: {resultado['falhas']}")
                    print(f"üèÜ Ranking: {resultado['total_ranking']} empresas")
                    print(f"üí° Aguardando releases no admin panel")
                    print(f"{'='*70}\n")
                    
                    return
                    
                except Exception as e:
                    print(f"\n‚ùå ERRO NA AN√ÅLISE INCREMENTAL: {e}")
                    import traceback
                    traceback.print_exc()
                    return
        
        print("‚ö†Ô∏è Nenhuma empresa aprovada encontrada")
        print("üí° Fa√ßa upload do CSV no admin panel para come√ßar")
        print(f"{'='*70}\n")
    
    def _salvar_empresas_aprovadas(self, empresas: List[str]):
        """Salva lista de empresas aprovadas"""
        try:
            os.makedirs("data", exist_ok=True)
            
            dados = {
                "timestamp": datetime.now().isoformat(),
                "total": len(empresas),
                "empresas": empresas,
                "fonte": "consenso_automatico",
                "detalhes": [
                    {"ticker": ticker, "nome": ticker}
                    for ticker in empresas
                ]
            }
            
            with open(self.empresas_file, 'w', encoding='utf-8') as f:
                json.dump(dados, f, indent=2, ensure_ascii=False)
            
            print(f"‚úì Empresas aprovadas salvas: {self.empresas_file}")
            
        except Exception as e:
            print(f"‚ùå Erro ao salvar empresas: {e}")
    
    def detectar_releases_novos(self) -> List[str]:
        """
        Detecta quais empresas t√™m releases novos
        
        Returns:
            Lista de tickers com releases novos
        """
        from app.services.release_manager import get_release_manager
        
        release_manager = get_release_manager()
        
        # Carrega empresas aprovadas
        if not os.path.exists(self.empresas_file):
            return []
        
        with open(self.empresas_file, 'r', encoding='utf-8-sig') as f:
            dados = json.load(f)
        
        empresas = dados.get("empresas", [])
        
        # Verifica quais t√™m releases
        empresas_com_releases = []
        for ticker in empresas:
            release = release_manager.obter_release_mais_recente(ticker)
            if release:
                empresas_com_releases.append(ticker)
        
        return empresas_com_releases
    
    async def atualizar_ranking_automaticamente(self):
        """
        Atualiza ranking automaticamente quando detecta releases novos
        
        Chamado periodicamente ou quando admin faz upload
        """
        print(f"\nüîÑ Verificando releases novos...")
        
        empresas_com_releases = self.detectar_releases_novos()
        
        if not empresas_com_releases:
            print("   Nenhum release novo detectado")
            return
        
        print(f"   ‚úì {len(empresas_com_releases)} empresas com releases")
        print(f"   Executando an√°lise incremental...")
        
        # Executa an√°lise incremental
        from app.services.analise_automatica import get_analise_automatica_service
        
        service = get_analise_automatica_service()
        
        # Carrega todas as empresas aprovadas
        with open(self.empresas_file, 'r', encoding='utf-8-sig') as f:
            dados = json.load(f)
        
        empresas = dados.get("empresas", [])
        
        resultado = await service.analisar_incrementalmente(
            empresas=empresas,
            forcar_reanalise=False,
            max_paralelo=3
        )
        
        print(f"   ‚úÖ Ranking atualizado!")
        print(f"      Novas an√°lises: {resultado['novas_analises']}")
        print(f"      Cache mantido: {resultado['cache_mantido']}")
        print(f"      Total no ranking: {resultado['total_ranking']}")


# Singleton
_sistema_automatico = None

def get_sistema_automatico() -> SistemaAutomatico:
    """Retorna inst√¢ncia singleton"""
    global _sistema_automatico
    if _sistema_automatico is None:
        _sistema_automatico = SistemaAutomatico()
    return _sistema_automatico
