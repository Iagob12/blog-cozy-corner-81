# üîç Problemas Encontrados em Runtime

Data: 20/02/2026 01:55

## ‚úÖ O Que Est√° Funcionando

1. ‚úÖ **Multi Groq Client** - Rota√ß√£o autom√°tica OK
2. ‚úÖ **Detec√ß√£o de Rate Limit** - Detecta 429 e marca chave
3. ‚úÖ **Sistema de Espera** - Aguarda quando todas em rate limit
4. ‚úÖ **Pesquisa Web** - 28/30 conclu√≠das (93%)
5. ‚úÖ **Contexto Persistente** - Mant√©m informa√ß√µes
6. ‚úÖ **Delay entre requisi√ß√µes** - 0.5s funcionando

---

## ‚ö†Ô∏è PROBLEMA CR√çTICO: Paralelismo Excessivo

### Problema:
```
[01:55:45] Todas as chaves em rate limit. Aguardando 5s... (tentativa 1/12)
[01:55:46] Todas as chaves em rate limit. Aguardando 5s... (tentativa 1/12)
[01:55:46] Todas as chaves em rate limit. Aguardando 5s... (tentativa 1/12)
```

### Causa:
- Sistema faz 30 pesquisas web SIMULT√ÇNEAS (uma por empresa)
- Temos apenas 6 chaves Groq
- Cada chave tem limite de 30 req/min
- 30 requisi√ß√µes paralelas esgotam todas as 6 chaves em segundos

### Impacto:
- ‚ö†Ô∏è An√°lise muito lenta (aguarda 60s m√∫ltiplas vezes)
- ‚ö†Ô∏è Todas as chaves ficam bloqueadas ao mesmo tempo
- ‚ö†Ô∏è Sistema funciona mas demora muito

### Solu√ß√£o:
**Implementar sistema de lotes (batches) para pesquisa web:**

```python
# ANTES (atual):
# Faz 30 pesquisas simult√¢neas
tasks = [pesquisar_empresa(e) for e in empresas]  # 30 tasks
resultados = await asyncio.gather(*tasks)

# DEPOIS (proposto):
# Faz 6 pesquisas por vez (uma por chave)
BATCH_SIZE = 6
for i in range(0, len(empresas), BATCH_SIZE):
    batch = empresas[i:i+BATCH_SIZE]
    tasks = [pesquisar_empresa(e) for e in batch]
    resultados_batch = await asyncio.gather(*tasks)
    # Aguarda 2s entre lotes
    await asyncio.sleep(2)
```

**Benef√≠cios:**
- ‚úÖ Usa 1 chave por empresa (6 simult√¢neas)
- ‚úÖ N√£o esgota todas as chaves de uma vez
- ‚úÖ An√°lise mais r√°pida (n√£o precisa aguardar 60s)
- ‚úÖ Mais eficiente

---

## ‚ö†Ô∏è PROBLEMA MENOR: CSV Desatualizado

### Problema:
```
CSV muito antigo: 24.2h (m√°ximo: 24h)
```

### Causa:
- Scraper de investimentos.com.br n√£o conseguiu baixar CSV novo
- Todas as URLs testadas falharam
- Scraping da p√°gina tamb√©m falhou

### Impacto:
- ‚ö†Ô∏è Dados de ontem (aceit√°vel mas n√£o ideal)
- ‚ö†Ô∏è Pode ter a√ß√µes com dados desatualizados

### Solu√ß√£o Tempor√°ria:
- ‚úÖ Aumentado limite para 48h
- ‚úÖ Sistema continua funcionando

### Solu√ß√£o Definitiva:
1. Melhorar scraper com mais URLs
2. API alternativa para dados fundamentalistas
3. Fallback para yfinance ou outras fontes

---

## ‚ö†Ô∏è PROBLEMA MENOR: Nenhum Release Encontrado

### Problema:
```
‚ö† PRIO3: Release n√£o encontrado (tentou Q4‚ÜíQ3‚ÜíQ2‚ÜíQ1 2025)
‚ö† B3SA3: Release n√£o encontrado (tentou Q4‚ÜíQ3‚ÜíQ2‚ÜíQ1 2025)
... (30/30 empresas)
```

### Causa:
- Releases de Q4 2025 ainda n√£o publicados (estamos em fevereiro)
- Q3 2025 tamb√©m n√£o dispon√≠vel
- Sistema tentou Q4‚ÜíQ3‚ÜíQ2‚ÜíQ1 mas nenhum encontrado

### Impacto:
- ‚ö†Ô∏è Sistema usa pesquisa web para TODAS as 30 empresas
- ‚ö†Ô∏è Isso causa o problema de paralelismo excessivo

### Solu√ß√£o:
1. ‚úÖ Pesquisa web como fallback (j√° implementado)
2. ‚è≥ Ajustar datas de busca (Q3 2024, Q4 2024)
3. ‚è≥ Melhorar download de releases

---

## üìä M√©tricas Observadas

| M√©trica | Valor | Status |
|---------|-------|--------|
| Chaves Groq | 6 | ‚úÖ |
| Rate limit detectado | Sim (429) | ‚úÖ |
| Sistema de espera | Funcionando | ‚úÖ |
| Pesquisas web | 28/30 (93%) | ‚úÖ |
| Paralelismo | 30 simult√¢neas | ‚ö†Ô∏è MUITO |
| Tempo de espera | 60s por chave | ‚ö†Ô∏è |
| Releases encontrados | 0/30 (0%) | ‚ö†Ô∏è |

---

## üéØ Prioridades de Corre√ß√£o

### ALTA üî¥
1. **Implementar batches para pesquisa web**
   - Limitar a 6 pesquisas simult√¢neas
   - Processar em lotes
   - Aguardar entre lotes

### M√âDIA üü°
2. **Ajustar busca de releases**
   - Tentar Q3/Q4 2024 (n√£o 2025)
   - Melhorar download

3. **Melhorar scraper de CSV**
   - Mais URLs para tentar
   - API alternativa

### BAIXA üü¢
4. **Otimiza√ß√µes gerais**
   - Cache mais inteligente
   - Logs mais limpos

---

## üí° C√≥digo Proposto

### 1. Batches para Web Research

```python
# Em web_research_service.py

async def pesquisar_multiplas_empresas(
    self, 
    empresas: list[Dict],
    batch_size: int = 6  # NOVO: tamanho do lote
) -> Dict[str, Dict]:
    """
    Pesquisa m√∫ltiplas empresas EM LOTES
    
    Args:
        empresas: Lista de dicts com 'ticker' e 'nome'
        batch_size: Quantas pesquisas simult√¢neas (padr√£o: 6, uma por chave)
    
    Returns:
        Dict[ticker, resultado_pesquisa]
    """
    
    print(f"\nüîç Pesquisando {len(empresas)} empresas em lotes de {batch_size}...")
    
    pesquisas = {}
    
    # Processa em lotes
    for i in range(0, len(empresas), batch_size):
        batch = empresas[i:i+batch_size]
        lote_num = (i // batch_size) + 1
        total_lotes = (len(empresas) + batch_size - 1) // batch_size
        
        print(f"\nüì¶ Lote {lote_num}/{total_lotes}: {len(batch)} empresas")
        
        # Cria tasks para este lote
        tasks = []
        for empresa in batch:
            ticker = empresa.get('ticker', '')
            nome = empresa.get('nome', ticker)
            task = self.pesquisar_empresa_completo(ticker, nome)
            tasks.append(task)
        
        # Executa lote em paralelo
        resultados = await asyncio.gather(*tasks, return_exceptions=True)
        
        # Processa resultados
        for j, resultado in enumerate(resultados):
            if isinstance(resultado, Exception):
                ticker = batch[j].get('ticker', '')
                print(f"   ‚úó {ticker}: Erro - {resultado}")
                continue
            
            if resultado.get('success'):
                ticker = resultado['ticker']
                pesquisas[ticker] = resultado
        
        # Aguarda entre lotes (exceto no √∫ltimo)
        if i + batch_size < len(empresas):
            tempo_espera = 2
            print(f"   ‚è≥ Aguardando {tempo_espera}s antes do pr√≥ximo lote...")
            await asyncio.sleep(tempo_espera)
    
    print(f"\n‚úì {len(pesquisas)}/{len(empresas)} pesquisas conclu√≠das\n")
    
    return pesquisas
```

### 2. Ajustar Busca de Releases

```python
# Em release_downloader.py

async def buscar_release_mais_recente(self, ticker: str) -> Optional[Dict]:
    """
    Busca Release mais recente com fallback Q4 2024 ‚Üí Q3 2024 ‚Üí Q2 2024
    """
    
    # Tenta Q4 2024 (n√£o 2025!)
    release = await self.baixar_release(ticker, "Q4", 2024)
    if release:
        return release
    
    # Tenta Q3 2024
    release = await self.baixar_release(ticker, "Q3", 2024)
    if release:
        return release
    
    # Tenta Q2 2024
    release = await self.baixar_release(ticker, "Q2", 2024)
    if release:
        return release
    
    # Tenta Q1 2024
    release = await self.baixar_release(ticker, "Q1", 2024)
    if release:
        return release
    
    return None
```

---

## üöÄ Pr√≥ximos Passos

1. ‚úÖ Problemas identificados e documentados
2. ‚è≥ Implementar batches para web research
3. ‚è≥ Ajustar busca de releases para 2024
4. ‚è≥ Testar sistema com corre√ß√µes
5. ‚è≥ Monitorar performance

---

## üìù Observa√ß√µes

- Sistema est√° FUNCIONAL mas LENTO
- Rate limit control est√° funcionando perfeitamente
- Problema principal √© ESTRAT√âGICO (paralelismo excessivo)
- Solu√ß√£o √© simples: processar em lotes
- Com batches, an√°lise ser√° 3-4x mais r√°pida

**Conclus√£o: Sistema 80% perfeito, precisa de ajuste estrat√©gico no paralelismo.**
